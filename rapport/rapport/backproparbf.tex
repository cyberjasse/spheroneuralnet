\section{Équation de rétropropagation d'un RBF}\label{sec:eqrbf}
Les modifications à apporter aux paramètres d'un neurone $i$ vaut
\begin{equation}\label{eq:modifpoid}
 \Delta W_{ij} = -\eta \partiel{Q}{W_{ij}}
\end{equation}
\begin{equation}\label{eq:modifmu}
 \Delta \mu_{ij} = -\eta \partiel{Q}{\mu_{ij}}
\end{equation}
\begin{equation}\label{eq:modifsigma}
 \Delta \sigma_{ij} = \eta \partiel{Q}{\sigma_{ij}}
\end{equation}

D'abord déterminons le facteur $\partiel{Q}{W_{ij}}$ dans \eqref{eq:modifpoid}.
On est dans le cas où $i$ est un neurone de sortie.
Par \eqref{eq:Q}, $Q$ dépend de $\phi_i$.
Par \eqref{eq:sortiephi}, $phi_i$ dépend de $W_{ij}$.
Par le théorème de dérivée des fonctions composés,
\begin{equation}\label{eq:rbfsortie}
 \partiel{Q}{W_{ij}} = \partiel{Q}{\phi_i} \partiel{\phi_i}{W_{ij}}
\end{equation}
Par \eqref{eq:sortie1}, on sait que
\[\partiel{Q}{\phi_i} = (\phi_i - s_i)\]
Ensuite,
\begin{equation}\label{eq:poidgrad}
 \begin{split}
  \partiel{\phi_i}{W_{ij}} & = \partiel{\frac{\sum_{r=1}^{m}W_{ir}x_{j}}{\factnorm}}{W_{ij}}\\
  ~ & = \frac{1}{\factnorm} \partiel{\sum_{r=1}^{m}W_{ir}x_{j}}{W_{ij}}\\
  ~ & = \frac{x_j}{\factnorm}
 \end{split}
\end{equation}
Subsituons \eqref{eq:sortie1} et \eqref{eq:poidgrad} dans \eqref{eq:rbfsortie}.
\begin{equation}\label{eq:sortiegrad}
 \partiel{Q}{W_{ij}} = (\phi_i - s_i) \frac{x_j}{\factnorm}
\end{equation}
Et \eqref{eq:sortiegrad} dans \eqref{eq:modifpoid},
\[\Delta W_{ij} = -\eta (\phi_i - s_i) \frac{x_j}{\factnorm}\]\\

Déterminons maintenant le facteur $\partiel{Q}{\mu_{ik}}$ dans \eqref{eq:modifmu}. On est dans le cas où $i$ est un neurone caché.
$Q$ dépend de $\phi_i$ qui lui-même est fonction de $\mu_{ik}$. Par le théorème de dérivée de fonction composés,
\begin{equation}\label{eq:composemu}
 \partiel{Q}{\mu_{ik}} = \partiel{Q}{\phi_i} \partiel{\phi_i}{\mu_{ik}}
\end{equation}
On va déterminer la valeur de $\partiel{Q}{\phi_i}$ et puis de $\partiel{\phi_i}{\mu_{ik}}$.
Soit $j$ un neurone de sortie. On sait que $Q$ dépend de tous les $\phi_j$ et les $\phi_j$ dépendent de $\phi_i$. On sait donc que
\begin{equation}\label{eq:mufact1}
 \partiel{Q}{\phi_i} = \sum_{j} \partiel{Q}{\phi_j}\partiel{\phi_j}{\phi_i}
\end{equation}
Par \eqref{eq:sortie1}, on sait que
\[\partiel{Q}{\phi_j} = (\phi_j - s_j)\]
Et posons $x_r$ l'entrée de $j$ provenant de $i$, c'est à dire $\phi_i = x_r$.
Posons $n$ la dimension de l'entrée de $j$.
Posons aussi $R = \sum_{k=1}^{n}x_k$.
Pour trouver la valeur de $\partiel{\phi_j}{\phi_i}$, nous aurons besoin de trouver $\partiel{\frac{1}{R}}{x_k}$.
\begin{equation}\label{eq:1sr}
 \begin{split}
 \partiel{\frac{1}{R}}{x_k} & = \frac{-1}{R^2}\partiel{R}{x_k}\\
 ~ & = \frac{-1}{R^2} 1
 \end{split}
\end{equation}
Dès lors, utilisons \eqref{eq:1sr} pour simplifier l'équation suivante;
\begin{equation}\label{eq:phiiphij}
 \begin{split}
 \partiel{\phi_j}{\phi_i} & = \partiel{\phi_j}{x_r}\\
 ~ & = \partiel{\left(\frac{\sum_{k=1}^{n}W_{jk}x_k}{\sum_{k=1}{n}x_k}\right)}{x_r}\\
 ~ & = \partiel{\left(\frac{W_{j1}x_1}{R}\right)}{x_r} + \partiel{\left(\frac{W_{j2}x_2}{R}\right)}{x_r} + ... + \partiel{\left(\frac{W_{jr}x_r}{R}\right)}{x_r} + .. + \partiel{\left(\frac{W_{jn}x_n}{R}\right)}{x_r}\\
 ~ & = (W_{j1}x_1)\frac{-1}{R^2} + (W_{j2}x_2)\frac{-1}{R^2} + ... + \left[(W_{jr}x_r)\partiel{\frac{1}{R}}{x_r}+\partiel{(W_{jr}x_r)}{x_r}\frac{1}{R}\right] + ... + (W_{jn}x_n)\frac{-1}{R^2}\\
 ~ & = \left(\sum_{k=1}^{n}W_{jk}x_k\frac{-1}{R^2}\right)-W_{jr}x_r\frac{-1}{R^2} + \left[(W_{jr}x_r)\frac{-1}{R^2}+W_{jr}\frac{1}{R}\right]\\
 ~ & = \frac{-1}{R^2} \left[\left(\sum_{k=1}^{n}W_{jk}x_k\right)-W_{jr}x_r + (W_{jr}x_r) + W_{jr}(-R)\right]\\
 ~ & = \frac{1}{R^2} \left(W_{jr}R - \sum_{k=1}^{n}W_{jk}x_k\right)
 \end{split}
\end{equation}
On substitue \eqref{eq:sortie1} et \eqref{eq:phiiphij} dans \eqref{eq:mufact1} pour obtenir
\begin{equation}\label{eq:mufacto1}
 \partiel{Q}{\phi_i} = \sum_{j} (\phi_j - s_j) \frac{1}{R^2} \left(W_{jr}R - \sum_{k=1}^{n}W_{jk}x_k\right)
\end{equation}

Si nous calculons $\partiel{\phi_i}{\mu_{ik}}$, nous obtenons
\begin{equation}\label{eq:mufacto2}
 \partiel{\phi_i}{\mu_{ik}} = \phi_i \frac{x_k-\mu_{ik}}{\sigma_{ik}^2}
\end{equation}
Et en substituant \eqref{eq:mufacto1} et \eqref{eq:mufacto2} dans \eqref{eq:composemu},
\[\partiel{Q}{\mu_{ik}} = \left[\sum_{i}(\phi_j - s_j) \frac{1}{R^2} \left(W_{jr}R - \sum_{k=1}^{n}W_{jk}x_k\right)\right] \phi_i\frac{x_k-\mu_{ik}}{\sigma_{ik}^2}\]
Qu'on substitue dans \eqref{eq:modifmu}, on obtient la modification à appliquer sur $\mu_{ik}$:
\[\Delta\mu_{ik} = -\eta \left[\sum_{i}(\phi_j - s_j) \frac{1}{R^2} \left(W_{jr}R - \sum_{k=1}^{n}W_{jk}x_k\right)\right] \phi_i\frac{x_k-\mu_{ik}}{\sigma_{ik}^2}\]

Enfin déterminons le facteur $\partiel{Q}{\sigma_{ik}}$ dans \eqref{eq:modifsigma}. On est dans le cas où $i$ est un neurone caché.
$Q$ dépend de $\phi_i$ qui lui-même est fonction de $\sigma_{ik}$. Par le théorème de dérivée de fonction composés,
\begin{equation}\label{eq:composesigma}
 \partiel{Q}{\sigma_{ik}} = \partiel{Q}{\phi_i} \partiel{\phi_i}{\sigma_{ik}}
\end{equation}
Si nous calculons $\partiel{\phi_i}{\sigma_{ik}}$, nous obtenons
\begin{equation}\label{eq:sigmafacto2}
 \partiel{\phi}{\sigma_{ik}} = \phi_i \frac{(x_k-\mu_{ik})^2}{\sigma_{ik}^3}
\end{equation}
On peut substituer \eqref{eq:mufacto1} et \eqref{eq:sigmafacto2} dans \eqref{eq:composesigma}:
\[\left[\sum_{i}(\phi_j - s_j) \frac{1}{R^2} \left(W_{jr}R - \sum_{k=1}^{n}W_{jk}x_k\right)\right] \phi_i \frac{(x_k-\mu_{ik})^2}{\sigma_{ik}^3}\]
Qu'on substitue dans \eqref{eq:modifsigma}, on obtient la modification à appliquer sur $\sigma_{ik}$:
\[\Delta \sigma_{ik} = -\eta \left[\sum_{i}(\phi_j - s_j) \frac{1}{R^2} \left(W_{jr}R - \sum_{k=1}^{n}W_{jk}x_k\right)\right] \phi_i \frac{(x_k-\mu_{ik})^2}{\sigma_{ik}^3}\]