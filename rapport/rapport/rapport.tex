\documentclass[12pt,a4paper,oneside, titlepage]{article}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage[pdftex]{graphicx}
\usepackage[final]{pdfpages}
\usepackage[frenchb]{babel}
\usepackage{xspace}
\usepackage{lmodern}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{cite}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{booktabs}% http://ctan.org/pkg/booktabs
\usepackage{textcomp}% symbole degré
\newcommand{\tabitem}{~~\llap{\textbullet}~~}
\begin{document}
\input{../titlepage}
\input{../commands}
\spherotitle{Rapport}{Année 2016-2017}
\tableofcontents
\newpage
\input{introduction}

\newpage
\section{Théorie}
\subsection{Modèles de réseaux de neurones artificiels}
\terminologie
Tout d'abord, analysons les différents modèles de réseau de neurones artificiels éxistants afin de pouvoir sélectionner celui qui convient le mieux à notre application.
Les plus connus d'entre eux sont le perceptron multi-couche et la fonction à base radiale, tous deux non récurrents.
Ensuite nous verrons les réseaux de neurones récurrents qui approximent des fonctions qui peuvent dépendre de toutes les entrées précédentes.
Les terminologies utilisées proviennent de la littérature anglophone et tous ceux rencontrés sont répertoriés à la table \ref{terminologie}.
\newcommand{\ssstitle}[1]{\begin{center}\large\underline{#1}\normalsize\end{center}}
\input{mlp}
\input{rbf}
%\input{cnn}
\input{rnn}
%\input{cmac}

\input{surgeneralisation}

\input{architecture}

\newpage
\section{Implémentation et application}

\input{design}

\subsection{Choix du réseau}
%TODO Tableau de comparaison
Nous n'avons pas besoin d'un réseau de neurones récurrent.
Les commandes à appliquer ne dépendent pas de la vitesse, position et autres données fournies aux étapes précédentes.
Le réseau le mieux adapté pour notre problème est un réseau de neurones à base radial.
En effet, les \rbf sont moins sensibles au bruit que les \mlp \cite{adversarial,Gauthier}.%gauthier p 39,40
Car dans la couche cachée, chaque neurone envoit une sortie indiquant la proximité entre le vecteur d'entrée et son prototype.
Donc typiquement, la contribution à l'erreur est presque entièrement celle du neurone ayant son prototype le plus proche de l'entrée.
Les autres neurones cachés auront une modification insignifiante de l'écart-type et du prototype.\\

Un des inconvénients des \rbf est que le nombre de neurones cachés croît avec la dimension et la taille du vecteur d'entrée.
Ceci ne pose pas de problème dans notre cas car le nombre de dimensions est faible.

\subsection{Choix de la méthode}
Vu toutes les inconnues mécaniques du mouvement de la Sphero, il s'avère difficile d'établir une équation permettant de prédire de manière précise l'état suivant en fonction des commandes exécutées.
Nous préfèrons donc nous passer d'un modèle analytique.
Dans ce cas, nous ne pouvons pas utiliser la méthode de l'apprentissage spécialisé.
De plus, télécommander une Sphero pour suivre une trajectoire est très difficile pour un humain.
Utiliser un apprentissage par reproduction de contrôleur n'est donc pas envisageable.\\
Nous pouvons obtenir un maître distant à chaque étape et donc nous n'avons pas besoin de l'architecture de Nguyen et Widrow.\\
Le problème de convergence vers une solution triviale, impliqué dans le cas d'un apprentissage indirect (section \ref{sec:appindirect}) exclu l'utilisation de cette méthode dans le cadre de ce projet.\\

Il nous reste deux méthodes pour lesquelles l'adaptabilité est sacrifiée: l'apprentissage en deux phases et apprentissage utilisant un modèle différentiable.
Les deux sont envisageables. Les tests seront effectués toujours sur le même sol horizontal.\\

La méthode avec modèle différentiable apportera un nouveau facteur influençant la réussite du projet: la fiabilité du modèle.
Mais puisque le sytème ne change pas, lorsqu'on arrive à obtenir un modèle fiable, nous pouvons effectuer un apprentissage en-ligne qui permettra à la Sphero de parfaire le suivi d'une trajectoire si cette trajectoire est ammenée à être répétée.
Nous utiliserons dans un premier temps la méthode en deux phases pour obtenir un ensemble de paires cible/commande où la précision dépend seulement des capteurs et pas de la fiabilité d'un modèle.

\subsection{Les API}
Certaines API permettant l'envoi de commande et réception de message provenant de la Sphero sont disponibles.
Les APIs officiels sont disponibles en: \textbf{Objective-C}, \textbf{Swift}, \textbf{Android}.\cite{SDKofficiels}\\
Il existe également des APIs créés par la communauté disponibles en\cite{gosphero}: \textbf{C\#}, \textbf{JavaScript}, \textbf{Ruby}, \textbf{Python}\cite{pythonAPI}, \textbf{Arduino}, \textbf{C++}\cite{cppAPI}.\\
L'API choisie est l'API \textbf{C++} pour le langage de programmation connu et performant exécutable sur PC.
Malgré les apparences, cet API n'est pas modulaire concernant le streaming.
En effet, le streaming est démarré dès la connection de la Sphero et la lecture des messages de streaming récupérés ne fonctionne que pour le streaming configuré pour l'application que l'auteur voulait en faire.
C'est à dire que des accès à la mémoire se font sans considération des données demandées pour le streaming et ne permet donc que de récupérer la position et la vitesse.
De plus l'écoute des messages de streaming sont non bloquants car ils sont effectués dans un thread à part.
Il n'est donc pas possible, sans modifier l'API, d'utiliser les données reçues dès leur réception.
L'API a donc été modifiée pour récupérer les données qui nous intéressent dans le cadre de ce projet mais aussi pour effectuer le design pattern observer  et le faire hériter d'une interface d'objet capable de streamer.
(Voir la section \ref{sec:impcommander} sur l'implémentation du système de commande.)

Le langage \textbf{Qt} sera utilisé pour créer les interfaces graphiques.
Cela nous permet de créer facilement des interfaces munies de boutons, menus et fenêtres afin de tracer la trajectoire.
De plus, l'implémentation du réseau de neurones pourra être directement utilisée dans un script \textbf{Qt} puisqu'il s'agit d'une extension du c++.

L'API \textbf{Caffe} sera utilisé plus tard afin de modifier facilement l'architecture du réseau de neurones dans le module de commande sans recompilation.\cite{caffe}

\subsection{Implémentation d'un réseau de neurones}
Un \rbf a été implémenté. Bien que fonctionnel, ce n'est pas ce réseau qui est utilisé dans la version actuelle du système de commande de ce projet.
Il a néanmoins été utilisé durant la phase d'expérimentation.
\subsubsection{Propriété utilisée}
Afin d'expliquer la structure de l'implémentation du réseau de neurone, nous allons tout d'abord expliquer pourquoi l'implémentation d'un neurone est indépendant de sa position et du modèle du réseau de neurones.
Et grâce à cette propriété, nous pouvons donc connecter n'importe quelle couche de neurones avec une autre sans modifier l'implémentation.
Nous pourrions donc facilement passer à une méthode d'apprentissage par modèle différentiable (Section \ref{sec:appmodele}) si cela s'avère nécessaire.
De plus, l'implémentation d'un nouveau modèle non récursif comme le \mlp nécésitera juste l'implémentation des nouveaux neurones.
En résumé, l'implémentation d'un réseau \rbf se fera à partir d'une implémentation de réseau de neurones non récursif modulaire.\\

Deux fonctions sont nécessaires pour l'implémentation d'un neurone:
\begin{enumerate}
 \item Une fonction qui permet de générer la sortie à partir de ses entrées (compute).
 \item Une fonction permettant l'apprentissage par rétropropagation (backpropagation).
\end{enumerate}
La fonction qui génère la sortie n'a besoin que des sorties des neurones de la couche précédente.
Et si on observe le développement des formules de rétropropagation dans les annexes \ref{sec:eqmlp} et \ref{sec:eqrbf},
la fonction qui permet l'apprentissage n'a besoin que de la sortie générée précédemment (cela peut être gardé en mémoire) et la \emph{contribution à l'erreur} des neurones de la couche suivante.
Le terme de contribution à l'erreur fait réference au terme $\delta$ dans la formule de modification des poids d'un \mlp (Section \ref{sec:appmlp}).
En effet, pour tous les différents neurones que nous avons vu dans ce rapport, soit $p$ un paramètre à modifier pour l'apprentissage du neurone $i$.
Soit $f_i$ la fonction appliquée aux entrées du neurone $i$ afin de générer la sortie.
$p$ doit être modifié selon la formule suivante:
\[\Delta p_i = -\eta \partiel{Q}{p_i}\]
Et afin de calculer la valeur de $\partiel{Q}{p_i}$, deux facteurs sont à connaître: $\partiel{Q}{f_i}$ et $\partiel{f_i}{p_i}$.
Pour connaître le facteur $\partiel{f_i}{p_i}$, toutes les données dont nous avons besoin se trouvent dans l'implémentation du neurone $i$ si nous y enregistrons sa sortie précédente.
Tandis que pour le facteur $\partiel{Q}{f_i}$,
si le neurone $i$ est un neurone de sortie, alors $\partiel{Q}{f_i}$ est connu, il s'agit de la dérivée partielle de l'erreur entre $f_i$ et sa valeur atendue.
Sinon $$\partiel{Q}{f_i} = \sum_{k \in \text{couche suivate}}\partiel{Q}{f_k}\partiel{f_k}{f_i}$$
Et donc $\partiel{Q}{f_i}$ peut être calculé à partir d'une implémentation dans les neurones de la couche suivante.

\subsubsection{Diagramme de classe}
\begin{figure}
 \centering
 \includegraphics[width=\textwidth]{../../uml/neurondiag.png}
 \caption{Diagramme de classe du réseaux de neurones. \footnotesize Généré par \href{http://plantuml.com/class-diagram}{plantUML}}
 \label{fig:diagclasse}
\end{figure}
Dans le diagramme de classe, Figure \ref{fig:diagclasse}, dans la déclaration de la fonction \texttt{backpropagation()}, \texttt{errorContribution} est le facteur $\partiel{Q}{f_i}$.
Le tableau retourné est stocké dans \texttt{thisContribution}.
Pour chaque entrée $x_j$ du neurone $i$, la $j$\textsuperscript{ième} valeur du tableau retourné est $\partiel{Q}{f_i}\partiel{f_i}{x_j}$.
Ces valeurs sont utilisées pour effectuer la rétropropagation de la couche précédente.

\subsubsection{Limitation actuelle}
Dans la version actuelle de l'implémentation, les biais ne sont pas supportés, le MLP n'est pas encore fonctionnel et des fuites mémoires ont été détectés.
Les fuites mémoires sont dû à l'allocation de mémoire pour transmettre des valeurs d'une couche à l'autre dans \texttt{Net.cpp}.
L'opérateur \texttt{New} effectue une allocation dynamique et nécessite d'être libérée exlplicitement par le programmeur.

\input{command}

\input{experimentation}

\section{Conclusion}
Malgré que le projet ne soit pas arrivé à son terme, nous avons découvert que pour pouvoir piloter une Sphero avec un réseau de neurone, nous avons besoin de nouveaux attributs ou d'une autre achitecture de réseau de neurones.
En effet, malgré tous les problèmes rencontrés nuisant à la qualité des données récoltées (section \ref{sec:choixdesign} et \ref{sec:choixdesign}) ,
un réseau de neurone devrait être capable d'approximer une fonction même avec des imprécisions, ou, du moins, de converger vers une autres solution que la moyenne de toutes les sorties.
Les autres attributs qui peuvent être ajoutées sont la vitesse à atteindre, l'inclinaison gauche-droite, l'inclinaison arrière-avant et les commandes précédentes.

Le comportement étrange de Weka, section \ref{sec:realdataex}, nous a peut-être mis sur une mauvaise piste.
Pensant que le problème vient du réseau de neurones implémenté alors qu'il peut provenir des données.
Il faudrait donc à l'avenir éviter d'utiliser ce logiciel pour des tâches de régression.

Dans l'état actuel de ce projet, nous avons un système de commande commandant aléatoirement mais en effectuant des trajectoires naturelles.
Nous pouvons désormais éditer facilement l'architecture du réseau de neurones pour le système de commandes,
éditer des trajectoires,
ou encore integrer de nouvelles transformations de données ou de nouveaux modèles de Sphero virtuelles.

Enfin, le développement d'un réseau de neurones nous a permis de comprendre en détails son fonctionnement et une propriété qui les rend très modulaires.

\subsection*{Remerciements}
\noindent Je remercie Monsieur Pierre \textsc{Hauweele} de m'avoir proposé un projet qui est exactement dans le domaine que je voulais, de son aide et de la direction de mon projet.\\

\noindent Je remercie Monsieur Hadrien Mélot pour la direction de mon projet et de l'aide qu'il m'a apporté.\\

\noindent Je remercie Monsieur Tom Mens pour son feed-back et ses conseils sur la rédaction de ce rapport.\\

\noindent Je remercie Monsieur Gauvain Devillez pour m'avoir débloqué plusieurs fois dans la compilation et ses conseils.sec:realdataex

\bibliographystyle{unsrt-fr}%unsrt-fr pour reference fr par num. plainnat-fr ou frplain Pour reference fr par auteur et annee
\bibliography{../bibli}
\appendix

\input{backpropamlp}
\input{backproparbf}

\end{document}
